{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawler obtido do site https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7434436/\n",
    "\n",
    "Um primeiro conjunto de dados públicos do Twitter brasileiro e notícias do COVID-19 em português\n",
    "Tiago de Melo, e Carlos MS Figueiredo \n",
    "\n",
    "#### Resumo\n",
    "Neste artigo de dados, fornecemos uma coleção de 3.925.366 tweets e 18.413 notícias online sobre a discussão online sobre COVID-19 no Brasil. Os dados do Twitter foram coletados por meio da biblioteca Twitterscraper Python e foi considerado um conjunto de palavras-chave em português referentes ao COVID-19. Para facilitar a identificação de tweets que possuem hashtags, mídia e retuítes para pesquisadores ou entusiastas de dados, criamos três conjuntos de dados específicos para cada uma dessas categorias. As notícias do COVID-19 foram coletadas no portal UOL, o site brasileiro mais popular. Todos os dados foram coletados de janeiro a maio de 2020. Esses conjuntos de dados podem atrair a atenção de comunidades como ciência de dados, ciências sociais, processamento de linguagem natural, turismo, infodemiologia e saúde pública.\n",
    "\n",
    "Palavras-chave: COVID-19, Pandemia, Conjunto de dados, Twitter, Notícias, Português"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place where the files will be saved\n",
    "dir_output = 'terapages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory terapages already exists.\n"
     ]
    }
   ],
   "source": [
    "# Procedure to create a directory to save the pages\n",
    "try:\n",
    "    os.mkdir(dir_output)\n",
    "except OSError:\n",
    "    print (\"Directory %s already exists.\" % dir_output)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % dir_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of URLs gathered manually\n",
    "input_file = \"terauol-link.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "https://www.uol.com.br/vivabem/noticias/agencia-estado/2021/03/28/tecnologia-deveria-ser-aberta-para-qualquer-pais-fabricar-imunizantes.htm\n",
      "https://www.uol.com.br/vivabem/noticias/bbc/2021/03/28/efeitos-da-covid-21-dos-infectados-relataram-so-problemas-de-pele-diz-estudo-lesoes-nao-devem-ser-ignoradas.htm\n",
      "https://www.uol.com.br/vivabem/noticias/redacao/2021/03/23/coronavirus-permanece-ativo-por-mais-de-14-dias-em-alguns-pacientes.htm\n",
      "https://www.uol.com.br/vivabem/noticias/bbc/2021/03/20/covid-19-dificuldade-de-concentracao-e-memoria-fraca-podem-durar-meses-apos-infeccao-entenda.htm\n"
     ]
    }
   ],
   "source": [
    "terapages_collected = next(os.walk(dir_output))[2]\n",
    "\n",
    "with open(input_file) as infile:\n",
    "    for line in infile:\n",
    "        url = line.strip()\n",
    "        page_name = url.split('/')[-1]\n",
    "        if page_name in terapages_collected:\n",
    "            print (\"Page already collected.\")\n",
    "#            print (page_name)\n",
    "            continue\n",
    "        elif page_name.split('.')[-1] != \"htm\":\n",
    "            print (\"Link is not a pageLink não é uma página HTML\")\n",
    "            continue\n",
    "        print (url)\n",
    "        terapages = requests.get(url)\n",
    "        with open(dir_output + '/' + page_name, 'w') as f:\n",
    "            f.write(terapages.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o arquivo .csv e Lendo o Conteúdo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import codecs\n",
    "import datetime\n",
    "import json\n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"terauol-link.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedure to get the list of pages collected previously\n",
    "d = {}\n",
    "with open(input_file) as infile:\n",
    "    for line in set(infile):\n",
    "        url = line.strip()\n",
    "        page_name = url.split('/')[-1]\n",
    "        day = line.strip().split('/')[-2]\n",
    "        month = line.strip().split('/')[-3]\n",
    "        year = line.strip().split('/')[-4]\n",
    "        try:\n",
    "            data_page = datetime.datetime.strptime(day + '-' + month + '-' + year, '%d-%m-%Y')\n",
    "        except:\n",
    "            None\n",
    "        if data_page.month > 5 or  data_page.year < 2020:\n",
    "            None\n",
    "        else:\n",
    "            d[page_name] = [url, str(data_page)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedure to create a structure (d) with the data collected\n",
    "dir_input = \"terapages\"\n",
    "pages_collected = next(os.walk(dir_input))[2]\n",
    "for page in pages_collected:\n",
    "    if not page in d.keys():\n",
    "        continue\n",
    "    text_uol = []\n",
    "    soup = BeautifulSoup(open(dir_input + '/' + page), \"html.parser\")\n",
    "    divTag = soup.find_all(\"div\", {\"class\": \"text\"})\n",
    "    for tag in divTag:\n",
    "        tdTags = tag.find_all(\"p\")\n",
    "        for tag in tdTags:\n",
    "            if len(tag.text) < 10:\n",
    "                continue\n",
    "            text_uol.append(tag.text)\n",
    "    d[page].append(text_uol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedure to save the data into file terauol-dataframe.csv\n",
    "header = ['date', 'title', 'url', 'text']\n",
    "with open(\"terauol-dataframe.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(header) # write the header\n",
    "    content = []\n",
    "    for k,v in d.items():\n",
    "        if len(v) == 2:\n",
    "            continue\n",
    "        url = v[0]\n",
    "        title = url.split('/')[-1].split('.')[0].replace('-', ' ')\n",
    "        data_page = v[1]\n",
    "        text_uol = v[2]\n",
    "        line = data_page, title, url, text_uol\n",
    "        content.append(line)\n",
    "    # write the actual content line by line\n",
    "    newL = sorted(content, key=lambda x: x[0], reverse=False)\n",
    "    for l in newL:\n",
    "        writer.writerow(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o arquivo .csv e Imprimindo uma saída para verificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para ver conteudo das variaveis\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date                                              title  \\\n",
      "0  2020-04-14 00:00:00     coronavirus fmi preve contracao economica de 3   \n",
      "1  2021-03-11 00:00:00                           remedios contra covid 19   \n",
      "2  2021-03-20 00:00:00  covid 19 dificuldade de concentracao e memoria...   \n",
      "3  2021-03-23 00:00:00   tratamento precoce covid cloroquina nao funciona   \n",
      "4  2021-03-23 00:00:00  coronavirus permanece ativo por mais de 14 dia...   \n",
      "5  2021-03-28 00:00:00  efeitos da covid 21 dos infectados relataram s...   \n",
      "6  2021-03-28 00:00:00  covid 19 trombose pode acontecer ate quatro se...   \n",
      "7  2021-03-28 00:00:00  tecnologia deveria ser aberta para qualquer pa...   \n",
      "8  2021-03-30 00:00:00  4 boas noticias sobre novos tratamentos em tes...   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://noticias.uol.com.br/videos/afp/2020/04...   \n",
      "1  https://www.uol.com.br/vivabem/noticias/redaca...   \n",
      "2  https://www.uol.com.br/vivabem/noticias/bbc/20...   \n",
      "3  https://noticias.uol.com.br/confere/ultimas-no...   \n",
      "4  https://www.uol.com.br/vivabem/noticias/redaca...   \n",
      "5  https://www.uol.com.br/vivabem/noticias/bbc/20...   \n",
      "6  https://www.uol.com.br/vivabem/noticias/redaca...   \n",
      "7  https://www.uol.com.br/vivabem/noticias/agenci...   \n",
      "8  https://www.uol.com.br/vivabem/noticias/bbc/20...   \n",
      "\n",
      "                                                text  \n",
      "0                                                 []  \n",
      "1  ['Após um ano da pandemia do novo coronavírus,...  \n",
      "2  ['Sintomas podem afetar as pessoas por meses a...  \n",
      "3  ['Há um ano, se luta contra a pandemia gerada ...  \n",
      "4  ['Estudos conduzidos no Instituto de Medicina ...  \n",
      "5  ['Lesão na pele pode servir tanto como um sina...  \n",
      "6  ['Uma pesquisa da Sociedade Brasileira de Angi...  \n",
      "7  ['Diante do risco de países pobres não consegu...  \n",
      "8  ['Corrida por medicamentos já levou ao registr...  \n"
     ]
    }
   ],
   "source": [
    "file_name = \"terauol-dataframe.csv\"\n",
    "df = pd.read_csv(file_name, encoding=\"ISO-8859-1\", usecols=[\"date\", \"title\", \"url\", \"text\"])\n",
    "df.to_csv('terauol-dataframe.csv')\n",
    "# print (df.head())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
