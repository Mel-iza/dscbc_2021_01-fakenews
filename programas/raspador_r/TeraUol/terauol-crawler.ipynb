{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawler obtido do site https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7434436/\n",
    "\n",
    "Um primeiro conjunto de dados públicos do Twitter brasileiro e notícias do COVID-19 em português\n",
    "Tiago de Melo, e Carlos MS Figueiredo \n",
    "\n",
    "#### Resumo\n",
    "Neste artigo de dados, fornecemos uma coleção de 3.925.366 tweets e 18.413 notícias online sobre a discussão online sobre COVID-19 no Brasil. Os dados do Twitter foram coletados por meio da biblioteca Twitterscraper Python e foi considerado um conjunto de palavras-chave em português referentes ao COVID-19. Para facilitar a identificação de tweets que possuem hashtags, mídia e retuítes para pesquisadores ou entusiastas de dados, criamos três conjuntos de dados específicos para cada uma dessas categorias. As notícias do COVID-19 foram coletadas no portal UOL, o site brasileiro mais popular. Todos os dados foram coletados de janeiro a maio de 2020. Esses conjuntos de dados podem atrair a atenção de comunidades como ciência de dados, ciências sociais, processamento de linguagem natural, turismo, infodemiologia e saúde pública.\n",
    "\n",
    "Palavras-chave: COVID-19, Pandemia, Conjunto de dados, Twitter, Notícias, Português"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place where the files will be saved\n",
    "dir_output = 'terapages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory terapages already exists.\n"
     ]
    }
   ],
   "source": [
    "# Procedure to create a directory to save the pages\n",
    "try:\n",
    "    os.mkdir(dir_output)\n",
    "except OSError:\n",
    "    print (\"Directory %s already exists.\" % dir_output)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % dir_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of URLs gathered manually\n",
    "input_file = \"terauol-link.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n",
      "Page already collected.\n"
     ]
    }
   ],
   "source": [
    "terapages_collected = next(os.walk('terapages'))[2]\n",
    "# terapages_collected = []\n",
    "\n",
    "with open(input_file) as infile:\n",
    "    for line in infile:\n",
    "        url = line.strip()\n",
    "        page_name = url.split('/')[-1]\n",
    "        if page_name in terapages_collected:\n",
    "            print (\"Page already collected.\")\n",
    "#            print (page_name)\n",
    "            continue\n",
    "        elif page_name.split('.')[-1] != \"htm\":\n",
    "            print (\"Link is not a pageLink não é uma página HTML\")\n",
    "            continue\n",
    "        print (url)\n",
    "        terapages = requests.get(url)\n",
    "        with open(dir_output + '/' + page_name, 'w') as f:\n",
    "            f.write(terapages.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o arquivo .csv e Lendo o Conteúdo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import codecs\n",
    "import datetime\n",
    "import json\n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"terauol-link.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'terauol-link.txt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedure to get the list of pages collected previously\n",
    "d = {}\n",
    "with open(input_file) as infile:\n",
    "    for line in set(infile):\n",
    "        url = line.strip()\n",
    "        page_name = url.split('/')[-1]\n",
    "        day = line.strip().split('/')[-2]\n",
    "        month = line.strip().split('/')[-3]\n",
    "        year = line.strip().split('/')[-4]\n",
    "        try:\n",
    "            data_page = datetime.datetime.strptime(day + '-' + month + '-' + year, '%d-%m-%Y')\n",
    "        except:\n",
    "            None\n",
    "        if data_page.month > 5 or  data_page.year < 2020:\n",
    "            None\n",
    "        else:\n",
    "            d[page_name] = [url, str(data_page)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedure to create a structure (d) with the data collected\n",
    "dir_input = \"terapages\"\n",
    "pages_collected = next(os.walk(dir_input))[2]\n",
    "\n",
    "# pages_collected = []\n",
    "\n",
    "for page in pages_collected:\n",
    "    if not page in d.keys():\n",
    "        continue\n",
    "    text_uol = []\n",
    "    soup = BeautifulSoup(open(dir_input + '/' + page), \"html.parser\")\n",
    "    divTag = soup.find_all(\"div\", {\"class\": \"text\"})\n",
    "    for tag in divTag:\n",
    "        tdTags = tag.find_all(\"p\")\n",
    "        for tag in tdTags:\n",
    "            if len(tag.text) < 10:\n",
    "                continue\n",
    "            text_uol.append(tag.text)\n",
    "    d[page].append(text_uol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procedure to save the data into file terauol-dataframe.csv\n",
    "header = ['date', 'title', 'url', 'text']\n",
    "with open(\"terauol.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(header) # write the header\n",
    "    content = []\n",
    "    for k,v in d.items():\n",
    "        if len(v) == 2:\n",
    "            continue\n",
    "        url = v[0]\n",
    "        title = url.split('/')[-1].split('.')[0].replace('-', ' ')\n",
    "        data_page = v[1]\n",
    "        text_uol = v[2]\n",
    "        line = data_page, title, url, text_uol\n",
    "        content.append(line)\n",
    "    # write the actual content line by line\n",
    "    newL = sorted(content, key=lambda x: x[0], reverse=False)\n",
    "    for l in newL:\n",
    "        writer.writerow(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo o arquivo .csv e Imprimindo uma saída para verificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para ver conteudo das variaveis\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"terauol.csv\"\n",
    "df = pd.read_csv(file_name, encoding=\"ISO-8859-1\", usecols=[\"date\", \"title\", \"url\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-11 00:00:00</td>\n",
       "      <td>remedios contra covid 19</td>\n",
       "      <td>https://www.uol.com.br/vivabem/noticias/redaca...</td>\n",
       "      <td>['Após um ano da pandemia do novo coronavírus,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-20 00:00:00</td>\n",
       "      <td>covid 19 dificuldade de concentracao e memoria...</td>\n",
       "      <td>https://www.uol.com.br/vivabem/noticias/bbc/20...</td>\n",
       "      <td>['Sintomas podem afetar as pessoas por meses a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-23 00:00:00</td>\n",
       "      <td>coronavirus permanece ativo por mais de 14 dia...</td>\n",
       "      <td>https://www.uol.com.br/vivabem/noticias/redaca...</td>\n",
       "      <td>['Estudos conduzidos no Instituto de Medicina ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-23 00:00:00</td>\n",
       "      <td>tratamento precoce covid cloroquina nao funciona</td>\n",
       "      <td>https://noticias.uol.com.br/confere/ultimas-no...</td>\n",
       "      <td>['Há um ano, se luta contra a pandemia gerada ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-28 00:00:00</td>\n",
       "      <td>tecnologia deveria ser aberta para qualquer pa...</td>\n",
       "      <td>https://www.uol.com.br/vivabem/noticias/agenci...</td>\n",
       "      <td>['Diante do risco de países pobres não consegu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-03-28 00:00:00</td>\n",
       "      <td>efeitos da covid 21 dos infectados relataram s...</td>\n",
       "      <td>https://www.uol.com.br/vivabem/noticias/bbc/20...</td>\n",
       "      <td>['Lesão na pele pode servir tanto como um sina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-03-28 00:00:00</td>\n",
       "      <td>covid 19 trombose pode acontecer ate quatro se...</td>\n",
       "      <td>https://www.uol.com.br/vivabem/noticias/redaca...</td>\n",
       "      <td>['Uma pesquisa da Sociedade Brasileira de Angi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-03-30 00:00:00</td>\n",
       "      <td>4 boas noticias sobre novos tratamentos em tes...</td>\n",
       "      <td>https://www.uol.com.br/vivabem/noticias/bbc/20...</td>\n",
       "      <td>['Corrida por medicamentos já levou ao registr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-03-31 00:00:00</td>\n",
       "      <td>como funciona a vacina da johnson aprovada par...</td>\n",
       "      <td>https://www.uol.com.br/vivabem/noticias/bbc/20...</td>\n",
       "      <td>['A Agência Nacional de Vigilância Sanitária (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-03-31 00:00:00</td>\n",
       "      <td>vivabem lanca campanha para conscientizar sobr...</td>\n",
       "      <td>https://economia.uol.com.br/noticias/redacao/2...</td>\n",
       "      <td>['Vacinas funcionam e são seguras. Para inspir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-04-02 00:00:00</td>\n",
       "      <td>como uma cidade paulista foi usada para testar...</td>\n",
       "      <td>https://www.uol.com.br/vivabem/noticias/redaca...</td>\n",
       "      <td>['O cotidiano dos moradores do pacato municípi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-04-02 00:00:00</td>\n",
       "      <td>entenda por que pessoas que vivem com hiv sera...</td>\n",
       "      <td>https://www.uol.com.br/vivabem/colunas/rico-va...</td>\n",
       "      <td>['Em nota técnica publicada no último dia 29 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-04-02 00:00:00</td>\n",
       "      <td>fda permite que vacina em temperatura ambiente...</td>\n",
       "      <td>https://www.uol.com.br/vivabem/noticias/agenci...</td>\n",
       "      <td>['A Moderna informou que a agência regulatória...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date                                              title  \\\n",
       "0   2021-03-11 00:00:00                           remedios contra covid 19   \n",
       "1   2021-03-20 00:00:00  covid 19 dificuldade de concentracao e memoria...   \n",
       "2   2021-03-23 00:00:00  coronavirus permanece ativo por mais de 14 dia...   \n",
       "3   2021-03-23 00:00:00   tratamento precoce covid cloroquina nao funciona   \n",
       "4   2021-03-28 00:00:00  tecnologia deveria ser aberta para qualquer pa...   \n",
       "5   2021-03-28 00:00:00  efeitos da covid 21 dos infectados relataram s...   \n",
       "6   2021-03-28 00:00:00  covid 19 trombose pode acontecer ate quatro se...   \n",
       "7   2021-03-30 00:00:00  4 boas noticias sobre novos tratamentos em tes...   \n",
       "8   2021-03-31 00:00:00  como funciona a vacina da johnson aprovada par...   \n",
       "9   2021-03-31 00:00:00  vivabem lanca campanha para conscientizar sobr...   \n",
       "10  2021-04-02 00:00:00  como uma cidade paulista foi usada para testar...   \n",
       "11  2021-04-02 00:00:00  entenda por que pessoas que vivem com hiv sera...   \n",
       "12  2021-04-02 00:00:00  fda permite que vacina em temperatura ambiente...   \n",
       "\n",
       "                                                  url  \\\n",
       "0   https://www.uol.com.br/vivabem/noticias/redaca...   \n",
       "1   https://www.uol.com.br/vivabem/noticias/bbc/20...   \n",
       "2   https://www.uol.com.br/vivabem/noticias/redaca...   \n",
       "3   https://noticias.uol.com.br/confere/ultimas-no...   \n",
       "4   https://www.uol.com.br/vivabem/noticias/agenci...   \n",
       "5   https://www.uol.com.br/vivabem/noticias/bbc/20...   \n",
       "6   https://www.uol.com.br/vivabem/noticias/redaca...   \n",
       "7   https://www.uol.com.br/vivabem/noticias/bbc/20...   \n",
       "8   https://www.uol.com.br/vivabem/noticias/bbc/20...   \n",
       "9   https://economia.uol.com.br/noticias/redacao/2...   \n",
       "10  https://www.uol.com.br/vivabem/noticias/redaca...   \n",
       "11  https://www.uol.com.br/vivabem/colunas/rico-va...   \n",
       "12  https://www.uol.com.br/vivabem/noticias/agenci...   \n",
       "\n",
       "                                                 text  \n",
       "0   ['Após um ano da pandemia do novo coronavírus,...  \n",
       "1   ['Sintomas podem afetar as pessoas por meses a...  \n",
       "2   ['Estudos conduzidos no Instituto de Medicina ...  \n",
       "3   ['Há um ano, se luta contra a pandemia gerada ...  \n",
       "4   ['Diante do risco de países pobres não consegu...  \n",
       "5   ['Lesão na pele pode servir tanto como um sina...  \n",
       "6   ['Uma pesquisa da Sociedade Brasileira de Angi...  \n",
       "7   ['Corrida por medicamentos já levou ao registr...  \n",
       "8   ['A Agência Nacional de Vigilância Sanitária (...  \n",
       "9   ['Vacinas funcionam e são seguras. Para inspir...  \n",
       "10  ['O cotidiano dos moradores do pacato municípi...  \n",
       "11  ['Em nota técnica publicada no último dia 29 d...  \n",
       "12  ['A Moderna informou que a agência regulatória...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
